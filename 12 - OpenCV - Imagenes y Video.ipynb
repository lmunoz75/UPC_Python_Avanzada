{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open CV - Imagenes y Video\n",
    "![](https://4.bp.blogspot.com/-Q0XriPVi_KQ/VG9LQyFIy3I/AAAAAAAADVE/pIGGVP3Ft_g/s1600/opencv-python.png)\n",
    "\n",
    "OpenCV (Open Source Computer Vision Library: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html) es una librería de código abierto que incluye varios cientos de algoritmos de computer vision. OpenCV2 4.x API esta basado en código escrito y compilado en C++.\n",
    "\n",
    "Luis A. Muñoz\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Nota sobre la instalación*\n",
    "Instalación del paquete OpenCV:\n",
    "\n",
    "    pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\asus\\anaconda3\\lib\\site-packages (4.5.5.62)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abrir una imagen\n",
    "OpenCV es una librería que permite importar imagenes de diferentes formatos. Una imagen se importa como un array n-dimensional. Una imagen en tonos de gris será un arreglo de *n x m*, según las dimensiones de la imagen. Una imagen en color será un arreglo de *n x m x c*, donde *c* será el número de canales de color. Esto quiere decír que cada uno de los tres arreglos contiene la información de la intensidad de los colores Rojos, Verde y Azul (la imagen puede tener un cuarto canal llamado *alpha-channel* que controla la transparencia de la imagen). \n",
    "\n",
    "![](https://ars.els-cdn.com/content/image/3-s2.0-B9780128230145000077-f03-08-9780128230145.jpg)\n",
    "\n",
    "OpenCV utiliza un mapa de colores diferentes al RGB: BGR (Blue, Green, Red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Open CV utiliza el mapa de colores BGR (no RGB)\n",
    "img = cv2.imread(\"img\\\\sample.jpg\", 1)  # 0 : Gray Scale (cv2.IMREAD_GRAYSCALE)\n",
    "                                    # >0: Return a 3-color image (cv2.IMREAD_COLOR)\n",
    "                                    # <0: Return the loaded image with alpha channel (cv2.IMREAD_UNCHANGED)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa, la imagen importada es un ndarray cuyas dimensiones dependerán de la imagen y de la forma como se ha interpretado la imagen. Aunque no hemos importado la librería *numpy*, tenemos acceso al arreglo y a sus propiedades y métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: (512, 512, 3)\n",
      "Dim: 3\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(\"Size:\", img.shape)    # Forma del arreglo numpy\n",
    "print(\"Dim:\", img.ndim)      # Numero de dimensiones\n",
    "print(img.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ventana de visualización de una imagen\n",
    "Para mostrar una imagen es necesario no solo adjuntar la imagen a una ventana con `cv2.imshow`, sino que debe declararse la forma de cerrar esta ventana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Sample Img\", img)\n",
    "cv2.waitKey(0)        # ms or 0 for close window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar un método sobre el arreglo imagen, podemos llamar a `resize` para ajustar las dimensiones del arreglo (y de la imagen), por medio de un proceso de interpolación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image = cv2.resize(img, (200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Resize Img\", resized_image)\n",
    "cv2.waitKey(0)        # ms or 0 for close window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ajustar el tamaño de una imagen suele ser común mantener la relación de aspecto (la proporción entre alto y ancho de una imagen). Para esto se puede extraer el tamaño original y operar dirctamente con estos valores. Hay que tener especial cuidado con el hecho de que las dimensiones de un arreglo se especifican como (filas, columnas), mientras que en el caso de una imagen se especifica como (ancho, alto), por lo que hay que invertír la asignación *(fila:alto, columna:ancho)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (341, 341, 3)\n"
     ]
    }
   ],
   "source": [
    "resized_image = cv2.resize(img, (int(img.shape[1]/1.5), int(img.shape[0]/1.5)))\n",
    "print(\"Shape:\", resized_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Resize Img\", resized_image)\n",
    "cv2.waitKey(0)        # ms or 0 for close window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar una imagen\n",
    "Podemos guardar una imagen utilizando el método `cv2.imwrite`. Este método retorna un valor booleano para confirmar el proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"img\\\\sample_res.jpg\", resized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abrir un video\n",
    "OpenCV también puede abrir archivos de video mp4 y avi. Para esto se genera un dispositivo de captura que toma el video como atributo de entrada y va extrayendo cada uno de los cuadros que componen en video para mostrarlos en secuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"img\\\\earth.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captura de una cámara\n",
    "OpenCV puede tener acceso a una camara web. En este caso, hay que ingresar el recurso de la cámara web como un valor entero en el dispositivo de captura de video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Configuracion de la resolucion (640x480) segun ID de configuracion\n",
    "# cap.set(3, 320)\n",
    "# cap.set(4, 240)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    cv2.imshow('WebCam Color', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIP: DroidCam\n",
    "En caso de no tener un cámara web, se puede utilizar la cámara de un teléfono móvil por medio de una aplicación que permita registrar el dispositivo como una cámara web. Se sugiere utiliza la aplicación [DroidCam](https://play.google.com/store/apps/details?id=com.dev47apps.droidcam&hl=es_PE) en equipos Android, e [ivCam](https://apps.apple.com/us/app/ivcam-webcam/id1164464478) en equipos Apple.\n",
    "\n",
    "Para el caso de DroidCam, se debe de modificar el código para lograr la conexión. Una vez instalada la aplicación, esta mostrará una pantalla donde mostrará la IP del teléfono en la red por la que podremos realizar la conexión. Hay que realizar la captura de la ruta `http://<direccion_ip>/mjpegfeed?640x480`. Esta dirección captura un fotograma que es procesado por OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Reemplazar por la IP del telefono\n",
    "cap = cv2.VideoCapture('http://192.168.1.10:4747/mjpegfeed?640x480')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    cv2.imshow('WebCam Color', frame)\n",
    "    cv2.imshow('WebCam Gray', gray)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar un video capturado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "codec = cv2.VideoWriter_fourcc(*'XVID')    # (*.\"MP4V\")\n",
    "out = cv2.VideoWriter('img\\\\cam_out.avi', codec, 20.0, (640, 480))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    out.write(frame)\n",
    "    \n",
    "    cv2.imshow('WebCam Color', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento básico de imagenes y video\n",
    "Con OpenCV se pueden manipular algunos aspectos de un imagen, como ya vimos anteriormente con la redefinición de su tamaño. Se puede convertir la imágen a gris (partiendo del mapa de colores BGR de OpenCV), rotar una imágen alrededor de un eje o rotarla un ángulo determinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img\\\\sample_res.jpg\")\n",
    "# Rotacion sobre un eje\n",
    "img_flipped = cv2.flip(img, 1)\n",
    "\n",
    "# Conversion a Escala de Grises\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Rotacion de una imagen (Matriz de Rotacion sobre el centro)\n",
    "(h, w) = img.shape[:2]\n",
    "center = (w/2, h/2)\n",
    "M = cv2.getRotationMatrix2D(center, 20, scale=1)\n",
    "img_rotated = cv2.warpAffine(img_gray, M, (w, h))\n",
    "\n",
    "# Se muestran las imagenes modificadas\n",
    "cv2.imshow(\"Original Img\", img)\n",
    "cv2.imshow(\"Flipped Image\", img_flipped)\n",
    "cv2.imshow(\"Gray Image\", img_gray)\n",
    "cv2.imshow(\"Rotated Image\", img_rotated)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las imagenes también se pueden utilizando filtros especiales, para desenfocar una imágen (blurring) y así eliminar el ruido, o detectar los bordes de una imágen (con el algoritmo de Canny) o realizar transformacion formológicas para conformar los bordes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "img = cv2.imread(\"img\\\\sample_res.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "img_blurred = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "img_border = cv2.Canny(img_blurred, 100, 200)    # Probar con img...\n",
    "img_dilated = cv2.dilate(img_border, kernel, iterations=1)\n",
    "img_eroded = cv2.erode(img_dilated, kernel, iterations=1)\n",
    "\n",
    "cv2.imshow(\"Blurred Img\", img_blurred)\n",
    "cv2.imshow(\"Border Img\", img_border)\n",
    "cv2.imshow(\"Border Dilated\", img_dilated)\n",
    "cv2.imshow(\"Border Eroded\", img_eroded)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insertar figuras y texto en un imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img\\\\sample.jpg\")\n",
    "\n",
    "cv2.line(img, pt1=(50, 20), pt2=(480, 20), color=(255, 0, 0), thickness=3)\n",
    "cv2.rectangle(img, pt1=(220, 200), pt2=(370, 400), color=(0, 255, 0), thickness=2)\n",
    "cv2.circle(img, center=(80, 400), radius=60, color=(0, 0, 255), thickness=-1)\n",
    "\n",
    "cv2.putText(img, text=\"OpenCV\", org=(200, 80), fontFace=cv2.FONT_HERSHEY_COMPLEX, \n",
    "            fontScale=1, color=(255, 255, 255), thickness=1)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de umbrales (escala de grises)\n",
    "Las imágenes en escala de grises son escenciales en el procesamiento de imagenes, ya que contienen la información del contenido visual en dos dimensiones (en lugar de las tres de una imagen a color), y mantiene la forma de los objetos. Para detectar estos será necesario en muchas oportunidades establecer un detector de umbral de valores (entre 0 y 255, es decir entre negro y blanco), de tal forma que se convierta una imágen de escala de grises en una imagen binaria de pixels blancos y negros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img\\\\logos.jpg\")\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# image, umbral, valor que reemplaza pixels sobre el umbral (255: blanco)\n",
    "thresh, bw_img = cv2.threshold(gray_img, 180, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Image Gray\", gray_img)\n",
    "cv2.imshow(\"Image_BW\", bw_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROI y cropping\n",
    "En procesamiento de imagenes, el ROI es el acrónimo de Region of Interest. Este concepto es importante ya que permite recordar que al momento de procesar una imagen, el proceso se concentra muchas veces sobre una región en particular y no sobre toda la imagen. Esto reduce el costo computacional del proceso.\n",
    "\n",
    "El cropping (recorte) es la extracción de una sección de la imagen, que puede ser el ROI o una parte que quiere procesarse de forma separada. El recorte de una imagen debe de realizarse en su forma matricial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img\\\\logos.jpg\")\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cropped_gray = img_gray[0:150, 0:160]   # row, cols\n",
    "cropped_color = img[0:150, 0:160, :]    # row, cols, colors\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Cropped Gray\", cropped_gray)\n",
    "cv2.imshow(\"Cropped Color\", cropped_color)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación: Detección de lineas de señalización\n",
    "Un uso fcada más más importante en las tareas de procesamiento en tiempo real de una imagen es en la detección de las lineas de señalización en un camino en los coches autónomos. La tarea del algoritmo es detectar las líneas que marcan un camino para que el automóvil no se salga de la pista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"img\\\\road.jpeg\")\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Image Gray\", img_gray)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para detectar las líneas de señalización, podemos convertir la imagen gris en binaria, de tal forma que resalten los bordes sobre el fondo negro, y filtrar la imagen con el filtro GaussianBlur para eliminar el ruido de los demas objetos (la vegetación del paisaje) para que no altere el proceso posterior de deteción de bordes (con el filtro Canny)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "img = cv2.imread(\"img\\\\road.jpeg\")\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "thresh, output = cv2.threshold(img_gray, 200, 255, cv2.THRESH_BINARY)\n",
    "output = cv2.dilate(output, kernel, iterations=1)\n",
    "output = cv2.GaussianBlur(output, (5, 5), 2)\n",
    "output = cv2.Canny(output, 180, 255)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Output\", output)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La imágen binaria obtenida la podemos pasar a un filtro especial llamado HoughLinesP, que detecta segmentos de recta en una imagen binaria utilizando [la transformación probabilistica de Hough](https://docs.opencv.org/3.4/d9/db0/tutorial_hough_lines.html). Luego, dibujaremos los segmentos detectados con cv2.line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "img = cv2.imread(\"img\\\\road.jpeg\")\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "thresh, output = cv2.threshold(img_gray, 200, 255, cv2.THRESH_BINARY)\n",
    "output = cv2.dilate(output, kernel, iterations=1)\n",
    "output = cv2.GaussianBlur(output, (5, 5), 2)\n",
    "output = cv2.Canny(output, 180, 255)\n",
    "\n",
    "# image, rho, theta, threshold\n",
    "lines = cv2.HoughLinesP(output, 1, np.pi/180, 20)\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La detección, una vez ajustado los parametros, es bastante buena, aunque se observa que detecta bordes en el cielo. Aquí es donde podemos recordar el ROI: la carretera siempre estará en la parte inferior, por lo que nuestro detector solo debe de reconocer patrones en la sección inferior, los 2/3 de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "img = cv2.imread(\"img\\\\road.jpeg\")\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Se extre el ROI en color y el gris\n",
    "h, w = img_gray.shape\n",
    "ROI_color = img[h // 3:, :, :]\n",
    "ROI_gray = img_gray[h // 3:, :]\n",
    "\n",
    "# Se realiza el procesamiento en ROI gris\n",
    "thresh, output = cv2.threshold(ROI, 200, 255, cv2.THRESH_BINARY)\n",
    "output = cv2.dilate(output, kernel, iterations=1)\n",
    "output = cv2.GaussianBlur(output, (5, 5), 2)\n",
    "output = cv2.Canny(output, 180, 255)\n",
    "\n",
    "# Se hace el trazado de las lineas en ROI color\n",
    "lines = cv2.HoughLinesP(output, 1, np.pi/180, 20)\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(ROI_color, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# Se \"parcha\" la imagen con el ROI color\n",
    "img[h // 3:, :, :] = ROI_color    \n",
    "    \n",
    "cv2.imshow(\"Image\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación: Insertar figuras en un video\n",
    "Este script se basa en la gestion de eventos del mouse por parte de OpenCV. Para esto es necesario crear una función que maneje el evento generado por el mouse que estará asociado a un evento gracias a la función cv2.setMouseCallback(window, func), donde func tiene una secuencia de parámetros fija y definida: lo único que cambia es lo que la función hace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "COLOR = (0, 0, 255)\n",
    "pt1 = (0, 0)\n",
    "pt2 = (0, 0)\n",
    "topLeft_clicked = False\n",
    "botRight_clicked = False\n",
    "\n",
    "def set_figure(event, x, y, flags, param):\n",
    "    global pt1, pt2, topLeft_clicked, botRight_clicked\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if topLeft_clicked and botRight_clicked:\n",
    "            pt1 = (0, 0)\n",
    "            pt2 = (0, 0)\n",
    "            topLeft_clicked = False\n",
    "            botRight_clicked = False\n",
    "            \n",
    "        if topLeft_clicked == False:\n",
    "            pt1 = (x, y)\n",
    "            topLeft_clicked = True\n",
    "        elif botRight_clicked == False:\n",
    "            pt2 = (x, y)\n",
    "            botRight_clicked = True\n",
    "\n",
    "# Se abre una ventana de video con opciones\n",
    "cv2.namedWindow('WebCam')\n",
    "# Se asocia un callback a la ventana (funcion)\n",
    "cv2.setMouseCallback('WebCam', set_figure)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Dibujar una figura en funcion de los parametros\n",
    "    if topLeft_clicked:\n",
    "        cv2.circle(frame, center=pt1, radius=1, color=COLOR, thickness=-1)\n",
    "        \n",
    "    if topLeft_clicked and botRight_clicked:\n",
    "        cv2.circle(frame, center=pt2, radius=1, color=COLOR, thickness=-1)\n",
    "        cv2.rectangle(frame, pt1, pt2, color=COLOR, thickness=3)\n",
    "    \n",
    "    cv2.imshow('WebCam', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIP: Listado de MouseEvents en OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVENT_FLAG_ALTKEY\n",
      "EVENT_FLAG_CTRLKEY\n",
      "EVENT_FLAG_LBUTTON\n",
      "EVENT_FLAG_MBUTTON\n",
      "EVENT_FLAG_RBUTTON\n",
      "EVENT_FLAG_SHIFTKEY\n",
      "EVENT_LBUTTONDBLCLK\n",
      "EVENT_LBUTTONDOWN\n",
      "EVENT_LBUTTONUP\n",
      "EVENT_MBUTTONDBLCLK\n",
      "EVENT_MBUTTONDOWN\n",
      "EVENT_MBUTTONUP\n",
      "EVENT_MOUSEHWHEEL\n",
      "EVENT_MOUSEMOVE\n",
      "EVENT_MOUSEWHEEL\n",
      "EVENT_RBUTTONDBLCLK\n",
      "EVENT_RBUTTONDOWN\n",
      "EVENT_RBUTTONUP\n"
     ]
    }
   ],
   "source": [
    "events = [i for i in dir(cv2) if 'EVENT' in i]\n",
    "for event in events: print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
